{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net for Semantic Image Segmentation\n",
    "#### Kaggle Competition (https://www.kaggle.com/c/cvpr-2018-autonomous-driving)\n",
    "#### Stanford course CS231n\n",
    "#### Aristos Athens (aristos@stanford.edu)\n",
    "#### Alice Li (ali2@stanford.edu)\n",
    "#### Amelia Bian (qb1@stanford.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import gc\n",
    "from PIL import Image\n",
    "\n",
    "import keras\n",
    "from keras.applications import vgg16, inception_v3, resnet50, mobilenet\n",
    "\n",
    "%matplotlib inline\n",
    "CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    \"\"\"\n",
    "    Object to hold all hyperparameters. Makes passing parameters between functions easier.\n",
    "    Many of these might not be strictly necessary.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # General params\n",
    "        self.data_type = tf.float32\n",
    "        self.root = '../data/cvpr-2018-autonomous-driving/train_color'\n",
    "        self.device = '/cpu:0'\n",
    "        \n",
    "        # Training params\n",
    "        self.optimizer = \"AdaGrad\" # options: Momentum, Adam, Adagrad\n",
    "        self.learning_rate = 1e-6\n",
    "        self.loss_type = \"fast\"  # options: \"fast\", \"full\"\n",
    "        self.momentum = 0.95\n",
    "        self.use_Nesterov = True\n",
    "        self.init_scale = 2.0\n",
    "        self.num_epochs = 10  # Total data to train on = num_epochs*batch_size\n",
    "        \n",
    "        # Data loader params\n",
    "        self.shuffle_data = True  # Currently doesn't do anything\n",
    "        self.preload = False\n",
    "        self.batch_size = 5\n",
    "        self.num_files_to_load = 200  # We require that num_files % batch_size = 0\n",
    "  \n",
    "        self.image_model = tf.global_variables_initializer()\n",
    "        \n",
    "              \n",
    "hp = HyperParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we create a customized data loader for the CVPR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVPR(object):\n",
    "    \"\"\"\n",
    "    A customized data loader for CVPR.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None, batch_size = 10):\n",
    "        \"\"\" Intialize the CVPR dataset\n",
    "        \n",
    "        Args:\n",
    "            - root: root directory of the dataset\n",
    "            - tranform: a custom tranform function\n",
    "            - preload: if preload the dataset into memory\n",
    "        \"\"\"\n",
    "        # Important - This tracks which batch we are on. Used for loading as we go (as opposed to preloading)\n",
    "        self.batch_num = 0\n",
    "        \n",
    "        # read filenames\n",
    "        self.filenames = []\n",
    "        filenames = glob.glob(osp.join(hp.root, '*.jpg'))\n",
    "        for fn in filenames:\n",
    "            lbl = fn[:-4] + '_instanceIds.png'\n",
    "            lbl = lbl.replace('color', 'label')\n",
    "            self.filenames.append((fn, lbl)) # (filename, label) pair\n",
    "            if len(self.filenames) >= hp.num_files_to_load: \n",
    "                break\n",
    "                \n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        if hp.preload:\n",
    "            self._preload()\n",
    "            \n",
    "        self.len = len(self.filenames)\n",
    "                              \n",
    "    def _preload(self):\n",
    "        \"\"\"\n",
    "        Preload dataset to memory\n",
    "        \"\"\"\n",
    "        for image_fn, label in self.filenames:\n",
    "            # load images\n",
    "            image = Image.open(image_fn)\n",
    "            self.images.append(np.asarray(image))            # avoid too many opened files bug\n",
    "            image.close()\n",
    "            # load labels\n",
    "            image = Image.open(label)\n",
    "            self.labels.append(np.asarray(image))             # avoid too many opened files bug\n",
    "            image.close()\n",
    "    \n",
    "        assert len(self.images) == len(self.labels), 'Got different numbers of data and labels'\n",
    "#         assert self.images[0].shape == self.labels[0].shape, 'Got data and labels with different shapes'\n",
    "\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        if self.images is not None:\n",
    "            # If dataset is preloaded\n",
    "            image = self.images[index]\n",
    "            label = self.labels[index]\n",
    "        else:\n",
    "            # If on-demand data loading\n",
    "            image_fn, label = self.filenames[index]\n",
    "            image = Image.open(image_fn)\n",
    "            label = Image.open(label)\n",
    "            \n",
    "        # May use transform function to transform samples\n",
    "        # e.g., random crop, whitening\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "        # return image and label\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        N, B = hp.num_files_to_load, hp.batch_size\n",
    "        return iter((self.images[i:i+B], self.labels[i:i+B]) for i in range(0, N, B))\n",
    "    \n",
    "    def update_iterator(self):\n",
    "        i = (self.batch_num-1)*hp.batch_size\n",
    "        i = max(0,i)\n",
    "        # If a batch has already been loaded free the last batch\n",
    "        if len(self.images) != 0:\n",
    "            for x in range(hp.batch_size-1):\n",
    "                self.images[i + x] = None\n",
    "                self.labels[i + x] = None\n",
    "        gc.collect()\n",
    "        i = self.batch_num*hp.batch_size\n",
    "        train_filenames = self.filenames[i:i + hp.batch_size]\n",
    "        self.batch_num += 1\n",
    "        for image_fn, label in train_filenames:\n",
    "            image = Image.open(image_fn)\n",
    "            self.images.append(np.asarray(image))            # avoid too many opened files bug\n",
    "            image.close()\n",
    "            image = Image.open(label)\n",
    "            self.labels.append(np.asarray(image))             # avoid too many opened files bug\n",
    "            image.close()\n",
    "    \n",
    "    def clear_iterator(self):\n",
    "        self.images[:] = None\n",
    "        self.labels[:] = None\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data set object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "data_set = CVPR(hp.root, transform = tf.convert_to_tensor)\n",
    "print(len(data_set))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show_image() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to show images\n",
    "# Takes an image as a tensor\n",
    "\n",
    "def show_image(hp, image_tensor):\n",
    "    with tf.Session() as session:\n",
    "        session.run(hp.image_model)\n",
    "        result = session.run(image_tensor)\n",
    "    plt.imshow(result)\n",
    "    plt.show()\n",
    "\n",
    "# Print a random example image\n",
    "if hp.preload:\n",
    "    index = random.randrange(0, len(data_set))\n",
    "    image, label = data_set.__getitem__(index)\n",
    "    show_image(hp, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(inputs, is_training):\n",
    "    \n",
    "    initializer = tf.variance_scaling_initializer(scale=hp.init_scale)\n",
    "    \n",
    "    # Transfer learning example here:\n",
    "    # https://deeplearningsandbox.com/how-to-use-transfer-learning-and-fine-tuning-in-keras-and-tensorflow-to-build-an-image-recognition-94b0b02444f2\n",
    "#     model = inception_v3.InceptionV3(weights='imagenet')\n",
    "#     model = vgg16.VGG16(weights='imagenet')\n",
    "#     model = resnet50.ResNet50(weights='imagenet')\n",
    "    \n",
    "    # Freeze weights in model - stops auto backprop on these layers\n",
    "#     for layer in model.layers:\n",
    "#         layer.trainable = False\n",
    "    \n",
    "    # Not 100% sure what this line does\n",
    "#     model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Add our own layers to the layers list within the model\n",
    "    input_shape = (2710, 3384, 3)\n",
    "    layers = [\n",
    "        tf.keras.layers.Conv2D(3, (3, 3), activation=\"relu\", kernel_initializer = initializer, input_shape=input_shape, padding = \"SAME\"),\n",
    "        tf.keras.layers.Conv2D(1, (5, 5), activation=\"relu\", kernel_initializer = initializer, padding = \"SAME\"),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "\n",
    "    return model(inputs)\n",
    "\n",
    "def create_optimizer(hp):\n",
    "    \n",
    "    optimizer = None\n",
    "    if hp.optimizer == \"Momentum\":    \n",
    "        optimizer = tf.train.MomentumOptimizer(learning_rate=hp.learning_rate, momentum=hp.momentum, use_nesterov=hp.use_Nesterov)\n",
    "    if hp.optimizer == \"Adam\":    \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=hp.learning_rate)\n",
    "    if hp.optimizer == \"AdaGrad\":\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=hp.learning_rate)\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training loop...\n",
      "Starting batch 0\n",
      "Batch 0 Loss = 913.5931 \n",
      "\n",
      "Starting batch 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7086022b79ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-7086022b79ba>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(hp, data_set, create_model, create_optimizer)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Batch %d Loss = %.4f \\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_net(hp, data_set, create_model, create_optimizer):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - create_model: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = create_model()\n",
    "    - create_optimizer: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = create_optimizer()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during training\n",
    "    \"\"\"\n",
    "#     tf.reset_default_graph()    \n",
    "    with tf.device(hp.device):\n",
    "        # Construct the computational graph we will use to train the model. We\n",
    "        # use the create_model to construct the model, declare placeholders for\n",
    "        # the data and labels\n",
    "        x = tf.placeholder(hp.data_type, [None, 2710, 3384, 3])\n",
    "        y = tf.placeholder(hp.data_type, [None, 2710, 3384])\n",
    "        \n",
    "        # We need a place holder to explicitly specify if the model is in the training\n",
    "        # phase or not. This is because a number of layers behaves differently in\n",
    "        # training and in testing, e.g., dropout and batch normalization.\n",
    "        # We pass this variable to the computation graph through feed_dict as shown below.\n",
    "        is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "        \n",
    "        # Use the model function to build the forward pass.\n",
    "        output = tf.squeeze(create_model(x, is_training))\n",
    "        \n",
    "        # First loss type is better, but second loss kind is much faster\n",
    "        if hp.loss_type == \"full\":\n",
    "            loss = tf.reduce_mean(tf.square(y - output))\n",
    "        if hp.loss_type == \"fast\":\n",
    "            loss = tf.reduce_mean(y - output)\n",
    "\n",
    "        # Use the create_optimizer to construct an Optimizer, then use the optimizer\n",
    "        # to set up the training step. Asking TensorFlow to evaluate the\n",
    "        # train_op returned by optimizer.minimize(loss) will cause us to make a\n",
    "        # single update step using the current minibatch of data.\n",
    "        \n",
    "        # Note that we use tf.control_dependencies to force the model to run\n",
    "        # the tf.GraphKeys.UPDATE_OPS at each training step. tf.GraphKeys.UPDATE_OPS\n",
    "        # holds the operators that update the states of the network.\n",
    "        # For example, the tf.layers.batch_normalization function adds the running mean\n",
    "        # and variance update operators to tf.GraphKeys.UPDATE_OPS.\n",
    "        \n",
    "        optimizer = create_optimizer(hp)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer_step = optimizer.minimize(loss)\n",
    "\n",
    "    # Now we can run the computational graph many times to train the model.\n",
    "    # When we call sess.run we ask it to evaluate train_op, which causes the model to update.\n",
    "    # # Total data to train on = num_epochs*batch_size\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        print(\"Starting training loop...\")\n",
    "        data_iterator = data_set.__iter__()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(hp.num_epochs):\n",
    "            print('Starting batch %d' % epoch)\n",
    "            data_set.update_iterator()\n",
    "            train_images, train_labels = next(data_iterator)\n",
    "            feed_dict = {x: train_images, y: train_labels, is_training: 1}\n",
    "            loss_value, _ = sess.run([loss, optimizer_step], feed_dict=feed_dict)\n",
    "            print('Batch %d Loss = %.4f \\n' % (epoch, loss_value))\n",
    "\n",
    "                \n",
    "train_net(hp, data_set, create_model, create_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
